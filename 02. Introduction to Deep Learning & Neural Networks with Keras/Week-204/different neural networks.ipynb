{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types based on depth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shallow neural network: The neural networks with typically 1 or 2 hidden layers\n",
    "- Deep neural network: The neural networks with many hidden layers with large neurons in each layer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.01.png\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similar to neural networks\n",
    "    - normal neural networks take N X 1  inputs for N no of columns\n",
    "    - CNNs take R X C X N  for R no of rows, C no of columns and N no of channels in an image\n",
    "- Takes inputs as images\n",
    "- Allows us to incorporate certain properties into the architecture for images\n",
    "    - Smooth forward propagation\n",
    "- Reduced parameters\n",
    "    - Convolution helps us to reduce parameters and fasten computation \n",
    "    - Helps us to retain special dimensions and informations\n",
    "- Working Process:\n",
    "    1. Convolution applies filters to sort out special dimensions\n",
    "    2. Pooling helps to extract significant pattern in the spatial dimension\n",
    "    3. Fully connected layer flattens the last Convolution or Pooling layer and connect with all the nodes of the flattenned layer with all the nodes in output layer in a dense manner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.02.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/01.03.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/01.04.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filter is slided through the pixels of an image\n",
    "- Sliding is done from left to right, up to down with a specified step size (stride)\n",
    "- It is the dot product of filter and the overlapping pixel values\n",
    "- Each filter creates a new reduced matrix from the original/previous pixel matrix\n",
    "- ReLU filters the output of convolution step\n",
    "    - Helps to retain positive information and discard negative information\n",
    "    - Overcomes the vanishing gradient problem introduced by sigmoid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/01.05.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/01.06.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retains the information within a specified region \n",
    "- Collects spatial variants that helps the neural network to identify patterns in images\n",
    "- Reduce the dimension by pooling out the sumarized information\n",
    "- Max pooling : Pool out the max value in the specified region\n",
    "- Average pooling : Pool out the average value in the specified region"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flatten output of last convolutional layer\n",
    "- Connect every node of the current layer with every other node in the next layer\n",
    "- eg: all nodes from convolution or pooling layer is connected with the next layers N number of nodes in output (for N classification problem) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# convert the target variable to categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(2,2), strides=(1,1), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=(2,2), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Categorical Crossentropy Loss:', loss)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.01.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Traditional neural networks take independent scenes as inputs\n",
    "- Recurrent neural networks incorporates dependency of sequence within a neural network\n",
    "- RNNs are networks with loops\n",
    "- All nodes compute: input_data * input_weight + previous_node_output * node_weight = new_output\n",
    "- example: LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.02.png\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is a data compression algorithm\n",
    "- Unsupervised neural network model\n",
    "- Uses back-propagation by setting target as same as input to train itself without using labels\n",
    "- It tries to find the approximation of the identity function\n",
    "- Neural networks use non-linear activation functions, so autoencoders can learn data projections that are more interesting than PCA or other basic techniques\n",
    "- Compression and de-compression functions are learned automatically from data\n",
    "- Data-specific (Only be able to compress data that they are trained on)\n",
    "- How it works:\n",
    "    - takes image as input\n",
    "    - use encoder to find optimal compressed representation of the input image\n",
    "    - Usse a decoder to restore the original image\n",
    "- example : RBM (Restricted Boltzmann Machine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
